import settingsStore from '@/features/stores/settings'
import { Message } from '@/features/messages/messages'
import { defaultModel } from '@/features/constants/aiModels'

const API_ENDPOINT = '/api/ai/vercel'

type RequestPayload = {
  messages: Message[]
  apiKey: string
  model: string
  stream: boolean
  useSearchGrounding: boolean
  dynamicRetrievalThreshold?: number
  temperature: number
  maxTokens: number
}

const buildRequestPayload = (messages: Message[], stream: boolean): RequestPayload => {
  const ss = settingsStore.getState()
  
  // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æœ€å¾Œã«ã€Œã‚µãƒ¼ãƒã€ã‚„ã€Œsearchã€ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
  let forceSearchGrounding = false
  if (!ss.slideMode) { // ä¼ç”»ä¸­ã¯ä½¿ç”¨ä¸å¯
    const lastUserMessage = messages
      .slice()
      .reverse()
      .find((msg) => msg.role === 'user')
    
    if (lastUserMessage) {
      const messageText = typeof lastUserMessage.content === 'string'
        ? lastUserMessage.content
        : lastUserMessage.content
            .filter((part) => part.type === 'text')
            .map((part) => part.text)
            .join(' ')
      
      // æœ€å¾Œã«ã€Œã‚µãƒ¼ãƒã€ã‚„ã€Œsearchã€ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã€ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠå•ã‚ãšï¼‰
      // ç©ºç™½ã‚„æ”¹è¡Œã‚’è€ƒæ…®ã—ã¦ã€ç¢ºå®Ÿã«æ¤œå‡ºã™ã‚‹
      const trimmedMessage = messageText.trim()
      const searchPattern = /(ã‚µãƒ¼ãƒ|ã•ãƒ¼ã¡|search|Search|SEARCH)(\s*)$/i
      if (searchPattern.test(trimmedMessage)) {
        forceSearchGrounding = true
        console.log('[vercelAIChat] âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ«å°¾ã«ã€Œã‚µãƒ¼ãƒã€æ¤œå‡ºã€ã‚µãƒ¼ãƒã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’å¼·åˆ¶æœ‰åŠ¹åŒ–', {
          messageText: trimmedMessage.substring(Math.max(0, trimmedMessage.length - 30)),
          fullMessage: trimmedMessage,
          matchedPattern: trimmedMessage.match(searchPattern)?.[0]
        })
      } else {
        console.log('[vercelAIChat] â„¹ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ«å°¾ã«ã€Œã‚µãƒ¼ãƒã€ãªã—:', {
          messageText: trimmedMessage.substring(Math.max(0, trimmedMessage.length - 30)),
          lastChars: trimmedMessage.slice(-10)
        })
      }
    }
  }
  
  const finalUseSearchGrounding = forceSearchGrounding || ss.useSearchGrounding
  
  console.log('[vercelAIChat] ğŸ“Š ã‚µãƒ¼ãƒã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°è¨­å®š:', {
    forceSearchGrounding,
    settingsUseSearchGrounding: ss.useSearchGrounding,
    finalUseSearchGrounding,
    slideMode: ss.slideMode
  })
  
  return {
    messages,
    apiKey: ss.googleKey,
    model: process.env.NEXT_PUBLIC_GOOGLE_MODEL || defaultModel,
    stream,
    useSearchGrounding: finalUseSearchGrounding,
    dynamicRetrievalThreshold: ss.dynamicRetrievalThreshold,
    temperature: ss.temperature,
    maxTokens: ss.maxTokens,
  }
}

const sendRequest = async (payload: RequestPayload) => {
  const response = await fetch(API_ENDPOINT, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(payload),
  })

  if (!response.ok) {
    const errorBody = await response.text()
    throw new Error(
      `Gemini API error (${response.status}): ${errorBody || 'Unknown'}`
    )
  }

  return response
}

export async function getVercelAIChatResponse(messages: Message[]) {
  const payload = buildRequestPayload(messages, false)
  const response = await sendRequest(payload)
  const data = await response.json()
  return { text: data.text }
}

export async function getVercelAIChatResponseStream(
  messages: Message[]
): Promise<ReadableStream<string>> {
  const payload = buildRequestPayload(messages, true)
  const response = await sendRequest(payload)
  if (!response.body) {
    throw new Error('Response body is empty')
  }
  
  // ReadableStream<Uint8Array> ã‚’ ReadableStream<string> ã«å¤‰æ›
  const decoder = new TextDecoder()
  const reader = response.body.getReader()
  
  return new ReadableStream<string>({
    async start(controller) {
      try {
        let allReceivedData = ''
        while (true) {
          const { done, value } = await reader.read()
          if (done) {
            console.log('[vercelAIChat] ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†ã€‚å—ä¿¡ã—ãŸå…¨ãƒ‡ãƒ¼ã‚¿:', {
              length: allReceivedData.length,
              preview: allReceivedData.substring(0, 500)
            })
            controller.close()
            break
          }
          const text = decoder.decode(value, { stream: true })
          allReceivedData += text
          console.log('[vercelAIChat] ãƒãƒ£ãƒ³ã‚¯å—ä¿¡:', {
            length: text.length,
            preview: text.substring(0, 200),
            totalLength: allReceivedData.length,
            fullText: text // ãƒ‡ãƒãƒƒã‚°ç”¨ã«å…¨æ–‡ã‚’è¡¨ç¤º
          })
          controller.enqueue(text)
        }
      } catch (error) {
        console.error('[vercelAIChat] ã‚¹ãƒˆãƒªãƒ¼ãƒ èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼:', error)
        controller.error(error)
      } finally {
        reader.releaseLock()
      }
    },
  })
}

